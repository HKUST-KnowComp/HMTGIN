Experiment dataset created by cleaning and sampling from the raw Stack Overflow data dump. It includes all questions whose numbers of answers are at least 8 and all associated nodes and edges.

	- JSON_Files/: the nodes and edges data stored in JSON format.

	- Edge_Indices/: Sample edge indices of all canonical edge types stored in .npy format. 

		- Node1_relation_Node2_Edge_Indices.npy: A 2-dimensional numpy array storing the sample edge indices of canonical edge type (Node1, relation, Node2). The first row stores the source node indices of all sample edges, and the second row stores the destination node indices of all sample edges.

	- Answer_Recommendation/: dataset of Answer Recommendation task (train: 67,789, dev: 8,474, test: 8,473)

	- Duplicate_Question_Detection/: dataset of Duplicate Question Detection task (train: 4,227, dev: 528, test: 528)

	- Answer_Score_Classification/: dataset of Answer Score Classification task (train: 969,846, dev: 121,231, test: 121,231)

	- Tag_Recommendation/: dataset of Tag Recommendation task (train: 762, 443, dev: 95,305, test: 95,304)

	- User_Reputation_Classification/: dataset of User Reputation Classification task (train: 618,813, dev: 77,352, test: 77,352)

	- Combined_Features_Embeddings/: combined feature embeddings stored in numpy arrays

	- Compressed_Combined_Features_Embeddings/: compressed combined feature embeddings from SVD (dimensions after compression are 16) on combined feature embeddings, the data are stored in numpy arrays

	- Non_Textual_Features_Embeddings/: non-textual features embeddings stored in numpy arrays

	- Textual_Features_Embeddings/: textual features embeddings stored in numpy arrays

	- Textual_Features_Pre_Processed_Values/: textual features pre-processed values (for text encoders) stored in json files

	- Combined_Features_Embeddings/: combined feature embeddings stored in numpy arrays

	- constraint_1_list.json: data for computing constraint 1 loss, stored in json file

	- constraint_2_list.json: data for computing constraint 2 loss, stored in json file


	-ID_Lists_and_Dictionaries/: Lists contain original node and edge ids. Dictionaries map original ids to indices in the corresponding lists.   
			
		- XX_ID_List.json (e.g., Sample_Clean_Answers_ID_List.json): List containing original ids of XX (e.g., Sample_Clean_Answers).

		- XX_ID_Dictionary.json (e.g., Sample_Clean_Answers_ID_Dictionary.json): Dictionary whose keys are original ids of XX, and the values are corresponding indices in XX_ID_List.json (e.g., Sample_Clean_Answers_ID_List.json).


	- Others/: Data for other auxiliary purposes.

		- Tags_Name_to_Original_ID_Dict.json: Dictionary whose keys are tags names and the values are corresponding original tag ids.


	- Word_to_Index_Dicts_and_Word_Embeddings/: word to index mappings and word embedding vectors.
	



	- Stat/ :  Files recording statistics.

		- Sample_PostLinks_Type_Stat_Dict.json: The key of each entry is one possible type of postlink (e.g., 'Q_L_A'), and the value is the count of corresponding postlinks in Sample_Clean_PostLinks.json. 'Q_L_A' means the type of the post corresponding to 'PostId' is question, and the type of the post corresponding to 'RelatedPostId' is answer, and the type of link is 'Linked'.

	- Pre-trained_Embeddings/ : node embeddings of Answers, Questions, and Users generated by training some baselines (e.g., BiLSTM) on some tasks (e.g., Answer Score Classification), embeddings are stored in pytorch tensors.




















	





 
